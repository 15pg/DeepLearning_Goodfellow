ML本质上属于应用统计学，更多地关注如何利用计算机统计地估计复杂函数。
ML不太关注为这些函数提供置信区间。

* 学习算法

**  任务
这里，任务是指如何处理样本。
ML可以解决很多类型的任务，
- 分类
- 回归
- 结构化 （转录、翻译、语法分析、图像分割等）


**  性能
我们更关注ML算法在未观测数据上的表现。
选择一个与系统理想表现相对应的性能度量通常是比较难的，这方面的设计应取决于应用。
还有一些情况，我们知道应该度量哪些指标，但实现起来不太现实。


**  经验
无监督学习试图学习出样本的概率分布，或者是该分布的一些有意思的性质；
监督学习观察输入的随机向量x及其标签y，然后试图从x预测y，通常是估计p(y|x)。

半监督学习处理只有部分样本有标签的情况。

有些ML算法并不是训练于一个固定的数据集上。例如，
强化学习算法会和环境交互，所以学习过程和它的训练过程会有反馈回路。
（本书不讨论这方面的内容——too bad）。。

数据集常表示为设计矩阵（宽表）。

有时候，标签会比较复杂，如训练语音模型转录整个句子时，每个句子的标签都是一个单词序列。


** 示例：线性回归
对每个输入的测试记录，对其各个特征做线性组合（各维分别乘以权重，然后求和），以估计其目标值（标签）。
这里，用均方误差度量模型的性能。

通过把误差函数对权重求偏导，求得临界点（极小值）处的权重向量。
书中把通过测试向量集及其标签集，求取权重的等式称为正规方程。

具体的，假设输入向量为x \in *R*^{n}，标签为y \in *R*，算法预测值为\hat{y}。
因为这里的算法是线性的，我们有
\hat{y}=x^{T}w，其中w \in *R*^{n}为算法的权重参量。

预测误差用均方误差度量，即E_{train}=\sum_{i=1..m}(\hat{y}_{i}-y_{i})^{2} /m，
其中，m为训练集中样本的个数。

模型训练时，我们的目标是使E_{train}尽可能地小。
上面式子可以看出，E是正定的，直接求其临界点即可:
- ∇_{w}E_{train} = 0  # 求E对w的临界点，要求的是w
- ∇_{w}\sum_{i=1..m}(\hat{y}_{i}-y_{i})^{2} /m = 0  # 代入
- ∇_{w}\sum_{i=1..m}(\hat{y}_{i}-y_{i})^{2} = 0  # 消除因子
- ∇_{w}(\hat{y}-y)^{T}(\hat{y}-y) = 0  # 写为向量形式
- ∇_{w}(Xw-y)^{T}(Xw-y) = 0  # 代入
- ∇_{w}((Xw)^{T}-y^{T})(Xw-y) = 0
- ∇_{w}((Xw)^{T}Xw-2y^{T}Xw+y^{T}y) = 0 # 注意，括号内为标量
- 2X^{T}Xw-2y^{T}X = 0
- w=(X^{T}X)^{-1}(X^{T}y)

关于偏置


*  泛化能力
与优化不同的是，ML中我们希望泛化误差尽可能地小（测试集等尚未观测到的数据集上的误差）。

当我们只用训练集训练模型时，如何才能影响到测试集上的性能？独立同分布假设。
（两个数据集中的样本是互相独立的，并且两个数据集同分布）。

决定ML算法效果好坏的依据：
- 训练误差小  （否则，欠拟合）
- 训练误差与测试误差的差值小  （否则，过拟合）


** 容量
容量是ML模型拟合各种函数的能力。
容量太低的模型容易导致欠拟合。
容量太高的模型又容易产生过拟合。

一种控制模型容量的方法，是选择假设空间，也就是选择ML算法的可使用的函数集。
比如引入x^{2}作为线性拟合的可用函数(注，此时模型的输出仍是w的线性函数，仍可用正规方程求解)。

奥卡姆剃刀


** VC维度
量化模型容量的方法。定义为二分类器能够将训练样本分类的最大分类数。(原来的翻译坑真不少。。)

统计学习理论中最重要的结论阐述了，训练误差与测试误差间差值的上界
随模型容量的增长而增长，随训练样本的增多而下降。

非参数模型，如最近邻回归


** 没有银弹
没有一个ML算法，在所有可能的数据分布上，都比其他的ML算法好。
（在考虑所有的数据分布后，所有的ML算法都一样好/一样糟。）


** 正则化
正则化是修改ML算法，使其泛化误差降低（而非训练误差）。
正则化是ML的中心议题之一，其重要性之高只有优化能与之相提并论。
正则化的思路之一是，给模型的目标函数/代价函数添加代表模型复杂程度的惩罚项（正则化项）。
DL的理念是，大量任务或许都可以使用非常通用的正则化项有效地解决。


** 超参数与验证集
大多数机器学习算法都有超参数，他们的值不是算法学习得到的。
不学习超参数，可能是由于太难优化，或者是他们不适合在训练集上学习（容易过拟合）等原因。

为了解决这个问题，需要有个不用于训练的验证集样本。
注意，用于评估学习效果的测试集中的样本不应以任何形式参与模型选择，包括设定超参数。
通常80%的数据用于训练，20%用于验证。

当可供使用的总数据量太小时，可以使用k折交叉验证。


* 估计、偏差、方差
统计领域为我们提供了很多工具用于量化机器学习目标。
诸如参数估计、偏差、方差等概念，对正式刻画泛化、欠拟合、过拟合都很有帮助。

点估计利用采样数据的函数来给出未知参数（标量或向量）的估计值，但也可能估计整个函数。
一般将参数\theta的点估计记为\hat{\theta}。

假设{x^{(1)}, ..., x^{(m)}}是对某个分布m次采样得到的数据点。
点估计是这些数据的任意函数， \hat{\theta}_{m} = g(x^{(1)}, ..., x^{(m)})。
一个良好估计量的输出会接近于生成数据的真实参数。

我们采用频率派在统计上的观点，假设真实参数\theta固定但未知，而点估计\hat{\theta}是数据的函数。
点估计也可以是输入和目标变量之间关系的估计，我们将这种类型的点估计称为函数估计。
函数估计\hat{f}是函数空间的一个点估计。


** 偏差
Bias(\hat{\theta}_m)=E(\hat{\theta}_m)-\theta

如果Bias(\hat{\theta}_m)=0，那么估计量\hat{\theta}_m被称为无偏的。
如果\lim_{m -> \infty}Bias(\hat{\theta}_m)=0，那么估计量\hat{\theta}_m被称为渐进无偏的。

高斯分布样本均值是\mu的无偏估计，而样本方差是则是高斯分布的有偏估计。

白努力分布的样本均值是其均值的无偏估计。
- Bias(\hat{\theta}_m) = E[\hat{\theta}_m] - \theta
- = E[\sum_{i=1..m}x^{i}/m] - \theta
- = E[\sum_{i=1..m}x^{i}]/m - \theta
- = \sum_{i=1..m}E[x^{i}]/m - \theta
- = \sum_{i=1..m}\sum_{x^(i)=0,1}(x^{i}\theta^{x^{i}}(1-\theta)^{1-x^{i}})/m - \theta
- = \sum_{i=1..m}\theta/m - \theta
- = \theta - \theta
- = 0

通常，我们更希望得到无偏估计，但它并不总是``最好''的估计。
我们经常会用到其他具有重要性质的有偏估计。


** 方差和标准差
统计量的方差Var(\hat{\theta})是另一重要性质；其方根称为标准差。

正如我们希望偏差较小一样，我们也希望方差较小。

样本方差的平方根和方差无偏估计的平方根都不是标准差的无偏估计。
他们都倾向于低估真实的标准差，但仍用于实际中。

均值的标准差记为
- SE(\hat{\mu}_{m})=sqrt(Var[\sum_{i=1..m}x^{i}/m])
- =\sigma/sqrt(m)

均值的标准差在ML实验中非常有用。我们常用测试集样本的误差均值来估计泛化误差。

中心极限定律告诉我们，均值会接近一个高斯分布。
可以用标准差计算出真实期望落在选定区间的概率。
- 置信区间


** 权衡偏差和方差以最小化均方误差
如果只可以选择一个偏差较大的估计，或者一个方差较大的估计，我们该如何选择？

这种权衡最常用的方法是交叉验证。
经验上，交叉验证efik真实世界的许多任务中都非常成功。
我们也可以比较这些估计的均方误差（同时包含了偏差和方差）。
- MSE=E[(\hat{\theta}_{m}-\theta)^{2}]
- =Bias(\hat{\theta}_{m})^{2}+Var(\hat{\theta}_{m})

偏差和方差的关系与机器学习容量、欠拟合、过拟合的概念紧密相联。
用MSE度量泛化误差时，增加容量会增加方差，降低偏差。


** 一致性
我们希望当数据集中数据点的数量m增加时，点估计会收敛到对应参数的真实值。
也就是所谓的一致性。一致性保证了估计量的偏差会随着数据样本数目的增多而减少。
（然而反过来不成立，渐进无偏不意味着一致性。比如构造一个估计量均值等于真实值的小的数据集。。）


* 最大似然法
我们需要有准则可以让我们从模型中得到特定函数作为好的估计，然后分析其偏差、方差。
而不是猜测某些函数可能是好的估计。
最常用的准则是最大似然估计。

考虑遗嘱包含m个样本的数据集X={x^{(1)},...,x^{(m)}}，独立地由未知的真实数据生成分布p_{data}(x)生成。
用p_{model}(x;\theta)将任意输入x映射到实数来估计真实概率p_{data}(x)。

对\theta的最大似然估计定义为
- \theta_{ML}=argmax_{\theta} p_{model}(X;\theta)
- =argmax_{\theta} \prod_{i=1..m}p_{model}(x^{i};\theta)

连乘可能导致数值下溢。
注意到似然对数不会改变argmax结果，但却可以将乘法转换为加法：
- \theta_{ML}=argmax_{\theta} \sum_{i=1..m} log p_{model}(x^{i};\theta)

又注意到缩放代价函数时，argmax不会改变。我们可以将其除以m，将求和转换为求期望：
- \theta_{ML}=argmax_{\theta} E_{X~\hat{p}_{data}} log p_{model}(x;\theta)

btw, 最小化KL散度可以获得与最大似然估计相同的argmax结果。


** 条件对数似然
最大似然估计很容易扩展到估计条件概率P(y|x;\theta)，从而给定x预测y。
实际上，这也是最常见的情况，因为这构成了大多数监督学习的基础。


** 最大似然的性质
- 一致性：在合适的条件下，最大似然估计具有一致性，也即，
      + 当训练样本数目趋于无穷大时，参数的估计值趋于真实值。
- 效率性：当m较大时，不存在MSE低于最大似然估计的一致估计。

鉴于这两点，最大似然估计是机器学习中首选的估计方法。


* 贝叶斯估计
利用贝叶斯规则来做估计。


** 最大后验估计MAP
MAP提供了一个直观的方法来设计复杂但可解释的正则化项。
例如，更复杂的惩罚项可以通过混合高斯分布作为先验得到，而不是一个单独的高斯分布。


* 监督学习算法
以后单独总结。


* 无监督算法
以后单独总结。


* 随机梯度下降

机器学习中的一个问题是，好的泛化需要大的训练集合。但大的训练集的计算代价也更大。
机器学习中，代价函数常可写为每个样本代价函数的总和。
当样本量很大时，计算一步梯度也会消耗相当长的时间。

随机梯度下降算法的思想是，利用小规模的样本近似估计梯度。
具体的，在算法的每一步，我们从训练集中均匀地抽出一小批量样本（m'个），去估计梯度。
m'相对较小，而且不随训练样本总数变化。
这样，在拟合几十亿样本时，每次更新计算可以只用几百个样本。


* 构建机器学习算法

* 促进机器学习发展的挑战
