ML本质上属于应用统计学，更多地关注如何利用计算机统计地估计复杂函数。
ML不太关注为这些函数提供置信区间。


* 学习算法

**  任务
这里，任务是指如何处理样本。
ML可以解决很多类型的任务，
- 分类
- 回归
- 结构化 （转录、翻译、语法分析、图像分割等）


**  性能
我们更关注ML算法在未观测数据上的表现。
选择一个与系统理想表现相对应的性能度量通常是比较难的，这方面的设计应取决于应用。
还有一些情况，我们知道应该度量哪些指标，但实现起来不太现实。


**  经验
无监督学习试图学习出样本的概率分布，或者是该分布的一些有意思的性质；
监督学习观察输入的随机向量x及其标签y，然后试图从x预测y，通常是估计p(y|x)。

半监督学习处理只有部分样本有标签的情况。

有些ML算法并不是训练于一个固定的数据集上。例如，
强化学习算法会和环境交互，所以学习过程和它的训练过程会有反馈回路。
（本书不讨论这方面的内容——too bad）。。

数据集常表示为设计矩阵（宽表）。

有时候，标签会比较复杂，如训练语音模型转录整个句子时，每个句子的标签都是一个单词序列。


**  示例：线性回归
对每个输入的测试记录，对其各个特征做线性组合（各维分别乘以权重），以估计其目标值（标签）。
这里，用均方误差度量模型的性能。

通过把误差函数对权重求偏导，求得临界点（极小值）处的权重向量。
书中把通过测试向量集及其标签集，求取权重的等式称为正规方程。
推导过程平淡无奇，有趣的是，书中把均方误差写成范数的平方，并转换为二次型。

关于偏置


*  泛化能力

** 容量

** 过拟合

** 欠拟合

